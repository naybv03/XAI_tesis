{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from quantus.metrics.faithfulness.faithfulness_estimate import FaithfulnessEstimate\n",
    "import quantus\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from utils.utils import load_dataset, save_explanation\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from models.roberta_model import classify_comment, load_roberta_model_main\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i hate that i cant change my cover photo on the app...\\r\\n', 'i have to go to the web for that and i cant organize my photos in certain albums only in the web!\\r\\n', \"i also can't change who views my information and stuff on my wall only in web...\\r\\n\", 'this version crashes all the time.\\r\\n', \"it's slow little bit.\\r\\n\", 'sd card storage need\\r\\n', \"it doesn't notify me of close friends updates.\\r\\n\", \"i can't post any comments or status updates from my motorola razr\\r\\n\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos\n",
    "# Ajusta la ruta según sea necesario\n",
    "dataset = load_dataset(\n",
    "    \"models/relevance_classification/dataset/facebook_labeled.csv\", sep=\",\")\n",
    "BATCH_SIZE = 8\n",
    "x_batch_dataset = dataset['Review'][:BATCH_SIZE]\n",
    "print(x_batch_dataset.to_list())\n",
    "# Cargar el modelo RoBERTa preentrenado\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# roberta_model = load_roberta_model_main()\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"modelo de ray mejorado(SHAP)/\")\n",
    "roberta_model.eval()  # Poner el modelo en modo de evaluación\n",
    "\n",
    "# Crear una instancia de la métrica Estimación de Fidelidad\n",
    "metric_fidelity = quantus.FaithfulnessEstimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability_techniques.lime import LIMEExplainer\n",
    "\n",
    "# Configurar el explicador LIME\n",
    "explainer_roberta = LIMEExplainer(class_names=['not relevant', 'relevant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar una instancia del conjunto de datos para explicar\n",
    "instance_roberta = dataset['Review'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generar la explicación usando LIME\n",
    "explanation_roberta = explainer_roberta.explain_instance(\n",
    "    instance_roberta,\n",
    "    classify_comment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_roberta = explanation_roberta.as_html()\n",
    "save_explanation(html_roberta, 'roberta_explanation.html')\n",
    "explainer_roberta.save_and_open_html(html_roberta, 'roberta_explanation.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 0.07903217621254756), (2, 0.057631094684298965), (6, 0.057631094684298965), (10, 0.05112344292713819), (5, 0.05112344292713819), (0, -0.02790873328540935), (9, -0.02790873328540935), (1, -0.02140108152824858), (8, 0.01524578594152915), (3, 0.0065076517571607696)] mapaaa\n",
      "Longitud de saliency_values para instancia 0: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 0.056028974225708995), (8, 0.03959431879583892), (3, -0.016434655429870063), (2, 0.014872613015319957), (5, 0.014872613015319957), (7, 0.014872613015319957), (12, 0.014872613015319957), (15, 0.014872613015319957), (0, -0.0015620424145501074), (1, -0.0015620424145501074)] mapaaa\n",
      "Longitud de saliency_values para instancia 1: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.04771176691899108), (4, 0.04771176691899108), (6, 0.04771176691899108), (13, 0.04771176691899108), (3, 0.032749638004805834), (9, 0.032749638004805834), (8, 0.0297853855729719), (5, -0.017926381346019187), (0, -0.014962128914185259), (1, -0.014962128914185259)] mapaaa\n",
      "Longitud de saliency_values para instancia 2: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.10963635903691758), (2, 0.10963635903691758), (4, 0.10963635903691758), (0, 0.07402626187881894), (5, -0.042553939283779554), (3, -0.03544798545144552)] mapaaa\n",
      "Longitud de saliency_values para instancia 3: 6\n",
      "[(1, 0.10963635903691758), (2, 0.10963635903691758), (4, 0.10963635903691758), (0, 0.07402626187881894), (5, -0.042553939283779554), (3, -0.03544798545144552), (-1, 0), (-1, 0), (-1, 0), (-1, 0)] ceroooooooooo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.26215534584957095), (3, 0.19730917210307503), (4, -0.08425559729279294), (0, -0.06484617374649602), (1, 0.034974621356730795)] mapaaa\n",
      "Longitud de saliency_values para instancia 4: 5\n",
      "[(2, 0.26215534584957095), (3, 0.19730917210307503), (4, -0.08425559729279294), (0, -0.06484617374649602), (1, 0.034974621356730795), (-1, 0), (-1, 0), (-1, 0), (-1, 0), (-1, 0)] ceroooooooooo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.15300128649749434), (3, 0.11108778801920827), (0, 0.07229618513139287), (1, -0.04191349847828613)] mapaaa\n",
      "Longitud de saliency_values para instancia 5: 4\n",
      "[(2, 0.15300128649749434), (3, 0.11108778801920827), (0, 0.07229618513139287), (1, -0.04191349847828613), (-1, 0), (-1, 0), (-1, 0), (-1, 0), (-1, 0), (-1, 0)] ceroooooooooo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.20063688355749343), (1, 0.1849094273712396), (2, 0.13877714220713055), (8, -0.058804561931325126), (7, -0.058804561931325126), (0, -0.046132285164109055), (4, 0.015727456186253822), (6, 0.015727456186253822), (5, 0.0030551794190377753)] mapaaa\n",
      "Longitud de saliency_values para instancia 6: 9\n",
      "[(3, 0.20063688355749343), (1, 0.1849094273712396), (2, 0.13877714220713055), (8, -0.058804561931325126), (7, -0.058804561931325126), (0, -0.046132285164109055), (4, 0.015727456186253822), (6, 0.015727456186253822), (5, 0.0030551794190377753), (-1, 0)] ceroooooooooo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Universidad\\informatica 4 año\\Semestre 1\\Precticas 2\\PP2_XAI\\models\\roberta_model.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(\n",
      "c:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.027255866017297826), (11, 0.027255866017297826), (1, 0.024431482334936507), (2, 0.024431482334936507), (10, 0.024431482334936507), (0, -0.006165582399263378), (6, -0.0028243836823613248), (8, -0.0028243836823613248), (9, -0.0028243836823613248), (12, -0.0028243836823613248)] mapaaa\n",
      "Longitud de saliency_values para instancia 7: 10\n",
      "[[(4, 0.07903217621254756), (2, 0.057631094684298965), (6, 0.057631094684298965), (10, 0.05112344292713819), (5, 0.05112344292713819), (0, -0.02790873328540935), (9, -0.02790873328540935), (1, -0.02140108152824858), (8, 0.01524578594152915), (3, 0.0065076517571607696)], [(9, 0.056028974225708995), (8, 0.03959431879583892), (3, -0.016434655429870063), (2, 0.014872613015319957), (5, 0.014872613015319957), (7, 0.014872613015319957), (12, 0.014872613015319957), (15, 0.014872613015319957), (0, -0.0015620424145501074), (1, -0.0015620424145501074)], [(2, 0.04771176691899108), (4, 0.04771176691899108), (6, 0.04771176691899108), (13, 0.04771176691899108), (3, 0.032749638004805834), (9, 0.032749638004805834), (8, 0.0297853855729719), (5, -0.017926381346019187), (0, -0.014962128914185259), (1, -0.014962128914185259)], [(1, 0.10963635903691758), (2, 0.10963635903691758), (4, 0.10963635903691758), (0, 0.07402626187881894), (5, -0.042553939283779554), (3, -0.03544798545144552), (-1, 0), (-1, 0), (-1, 0), (-1, 0)], [(2, 0.26215534584957095), (3, 0.19730917210307503), (4, -0.08425559729279294), (0, -0.06484617374649602), (1, 0.034974621356730795), (-1, 0), (-1, 0), (-1, 0), (-1, 0), (-1, 0)], [(2, 0.15300128649749434), (3, 0.11108778801920827), (0, 0.07229618513139287), (1, -0.04191349847828613), (-1, 0), (-1, 0), (-1, 0), (-1, 0), (-1, 0), (-1, 0)], [(3, 0.20063688355749343), (1, 0.1849094273712396), (2, 0.13877714220713055), (8, -0.058804561931325126), (7, -0.058804561931325126), (0, -0.046132285164109055), (4, 0.015727456186253822), (6, 0.015727456186253822), (5, 0.0030551794190377753), (-1, 0)], [(3, 0.027255866017297826), (11, 0.027255866017297826), (1, 0.024431482334936507), (2, 0.024431482334936507), (10, 0.024431482334936507), (0, -0.006165582399263378), (6, -0.0028243836823613248), (8, -0.0028243836823613248), (9, -0.0028243836823613248), (12, -0.0028243836823613248)]] saliency_list\n",
      "(8, 10, 2) a_batch_saliency\n",
      "[[[ 4.00000000e+00  7.90321762e-02]\n",
      "  [ 2.00000000e+00  5.76310947e-02]\n",
      "  [ 6.00000000e+00  5.76310947e-02]\n",
      "  [ 1.00000000e+01  5.11234429e-02]\n",
      "  [ 5.00000000e+00  5.11234429e-02]\n",
      "  [ 0.00000000e+00 -2.79087333e-02]\n",
      "  [ 9.00000000e+00 -2.79087333e-02]\n",
      "  [ 1.00000000e+00 -2.14010815e-02]\n",
      "  [ 8.00000000e+00  1.52457859e-02]\n",
      "  [ 3.00000000e+00  6.50765176e-03]]\n",
      "\n",
      " [[ 9.00000000e+00  5.60289742e-02]\n",
      "  [ 8.00000000e+00  3.95943188e-02]\n",
      "  [ 3.00000000e+00 -1.64346554e-02]\n",
      "  [ 2.00000000e+00  1.48726130e-02]\n",
      "  [ 5.00000000e+00  1.48726130e-02]\n",
      "  [ 7.00000000e+00  1.48726130e-02]\n",
      "  [ 1.20000000e+01  1.48726130e-02]\n",
      "  [ 1.50000000e+01  1.48726130e-02]\n",
      "  [ 0.00000000e+00 -1.56204241e-03]\n",
      "  [ 1.00000000e+00 -1.56204241e-03]]\n",
      "\n",
      " [[ 2.00000000e+00  4.77117669e-02]\n",
      "  [ 4.00000000e+00  4.77117669e-02]\n",
      "  [ 6.00000000e+00  4.77117669e-02]\n",
      "  [ 1.30000000e+01  4.77117669e-02]\n",
      "  [ 3.00000000e+00  3.27496380e-02]\n",
      "  [ 9.00000000e+00  3.27496380e-02]\n",
      "  [ 8.00000000e+00  2.97853856e-02]\n",
      "  [ 5.00000000e+00 -1.79263813e-02]\n",
      "  [ 0.00000000e+00 -1.49621289e-02]\n",
      "  [ 1.00000000e+00 -1.49621289e-02]]\n",
      "\n",
      " [[ 1.00000000e+00  1.09636359e-01]\n",
      "  [ 2.00000000e+00  1.09636359e-01]\n",
      "  [ 4.00000000e+00  1.09636359e-01]\n",
      "  [ 0.00000000e+00  7.40262619e-02]\n",
      "  [ 5.00000000e+00 -4.25539393e-02]\n",
      "  [ 3.00000000e+00 -3.54479855e-02]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.00000000e+00  2.62155346e-01]\n",
      "  [ 3.00000000e+00  1.97309172e-01]\n",
      "  [ 4.00000000e+00 -8.42555973e-02]\n",
      "  [ 0.00000000e+00 -6.48461737e-02]\n",
      "  [ 1.00000000e+00  3.49746214e-02]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.00000000e+00  1.53001286e-01]\n",
      "  [ 3.00000000e+00  1.11087788e-01]\n",
      "  [ 0.00000000e+00  7.22961851e-02]\n",
      "  [ 1.00000000e+00 -4.19134985e-02]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 3.00000000e+00  2.00636884e-01]\n",
      "  [ 1.00000000e+00  1.84909427e-01]\n",
      "  [ 2.00000000e+00  1.38777142e-01]\n",
      "  [ 8.00000000e+00 -5.88045619e-02]\n",
      "  [ 7.00000000e+00 -5.88045619e-02]\n",
      "  [ 0.00000000e+00 -4.61322852e-02]\n",
      "  [ 4.00000000e+00  1.57274562e-02]\n",
      "  [ 6.00000000e+00  1.57274562e-02]\n",
      "  [ 5.00000000e+00  3.05517942e-03]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 3.00000000e+00  2.72558660e-02]\n",
      "  [ 1.10000000e+01  2.72558660e-02]\n",
      "  [ 1.00000000e+00  2.44314823e-02]\n",
      "  [ 2.00000000e+00  2.44314823e-02]\n",
      "  [ 1.00000000e+01  2.44314823e-02]\n",
      "  [ 0.00000000e+00 -6.16558240e-03]\n",
      "  [ 6.00000000e+00 -2.82438368e-03]\n",
      "  [ 8.00000000e+00 -2.82438368e-03]\n",
      "  [ 9.00000000e+00 -2.82438368e-03]\n",
      "  [ 1.20000000e+01 -2.82438368e-03]]] a_batch_saliency\n",
      "(8,) x_batch_dataset\n",
      "0    i hate that i cant change my cover photo on th...\n",
      "1    i have to go to the web for that and i cant or...\n",
      "2    i also can't change who views my information a...\n",
      "3               this version crashes all the time.\\r\\n\n",
      "4                            it's slow little bit.\\r\\n\n",
      "5                             sd card storage need\\r\\n\n",
      "6    it doesn't notify me of close friends updates....\n",
      "7    i can't post any comments or status updates fr...\n",
      "Name: Review, dtype: object x_batch_dataset\n",
      "(8,) x_batch\n",
      "['i hate that i cant change my cover photo on the app...\\r\\n'\n",
      " 'i have to go to the web for that and i cant organize my photos in certain albums only in the web!\\r\\n'\n",
      " \"i also can't change who views my information and stuff on my wall only in web...\\r\\n\"\n",
      " 'this version crashes all the time.\\r\\n' \"it's slow little bit.\\r\\n\"\n",
      " 'sd card storage need\\r\\n'\n",
      " \"it doesn't notify me of close friends updates.\\r\\n\"\n",
      " \"i can't post any comments or status updates from my motorola razr\\r\\n\"] x_batch\n",
      "(8,) y_batch\n",
      "[1 1 1 1 1 1 1 1] y_batch\n",
      "['i hate that i cant change my cover photo on the app...\\r\\n', 'i have to go to the web for that and i cant organize my photos in certain albums only in the web!\\r\\n', \"i also can't change who views my information and stuff on my wall only in web...\\r\\n\", 'this version crashes all the time.\\r\\n', \"it's slow little bit.\\r\\n\", 'sd card storage need\\r\\n', \"it doesn't notify me of close friends updates.\\r\\n\", \"i can't post any comments or status updates from my motorola razr\\r\\n\"]\n",
      "torch.Size([8, 2])\n",
      "<built-in method type of Tensor object at 0x0000019D78A42580>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sympy import false\n",
    "\n",
    "\n",
    "\n",
    "# Generar explicaciones para todas las instancias del conjunto de datos\n",
    "\n",
    "\n",
    "saliency_list = []\n",
    "\n",
    "\n",
    "# Inicializar listas para almacenar las opiniones y etiquetas filtradas\n",
    "\n",
    "\n",
    "filtered_reviews = []\n",
    "\n",
    "\n",
    "filtered_labels = []\n",
    "\n",
    "\n",
    "\n",
    "# for index in range(len(dataset)):\n",
    "\n",
    "\n",
    "for index in range(x_batch_dataset.size):\n",
    "\n",
    "\n",
    "    instance_roberta = dataset['Review'].iloc[index]\n",
    "\n",
    "\n",
    "    # Generar la explicación usando LIME\n",
    "    explanation_roberta = explainer_roberta.explain_instance(\n",
    "        instance_roberta,\n",
    "        classify_comment  # Asegúrate de que esta función esté definida para clasificar el comentario\n",
    "    )\n",
    "\n",
    "\n",
    "    # Extraer las atribuciones de saliencia\n",
    "\n",
    "\n",
    "    # Obtiene las atribuciones de la clase relevante\n",
    "\n",
    "\n",
    "    saliency_values = explanation_roberta.as_map()[1]\n",
    "    print(saliency_values, \"mapaaa\")\n",
    "\n",
    "\n",
    "    if isinstance(saliency_values, list):\n",
    "\n",
    "\n",
    "        print(f\"Longitud de saliency_values para instancia {\n",
    "\n",
    "\n",
    "              index}: {len(saliency_values)}\")\n",
    "\n",
    "\n",
    "        # Solo agregar si tiene una longitud específica (por ejemplo, 10)\n",
    "\n",
    "\n",
    "        if len(saliency_values) == 10:\n",
    "\n",
    "\n",
    "            saliency_list.append(saliency_values)\n",
    "\n",
    "\n",
    "            # Agregar la reseña filtrada\n",
    "\n",
    "\n",
    "            filtered_reviews.append(instance_roberta)\n",
    "\n",
    "\n",
    "            # Agregar la etiqueta correspondiente\n",
    "\n",
    "\n",
    "            filtered_labels.append(dataset['Relevant'].iloc[index])\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Rellenar con ceros hasta llegar a 10\n",
    "            padded_saliency = saliency_values + \\\n",
    "                [(-1, 0)] * (10 - len(saliency_values))\n",
    "            print(padded_saliency, \"ceroooooooooo\")\n",
    "            saliency_list.append(padded_saliency)\n",
    "            # Agregar la reseña filtrada\n",
    "            filtered_reviews.append(instance_roberta)\n",
    "            # Agregar la etiqueta correspondiente\n",
    "            filtered_labels.append(dataset['Relevant'].iloc[index])\n",
    "\n",
    "print(saliency_list, \"saliency_list\")\n",
    "# a_batch_saliency = np.array(saliency_list)\n",
    "# print(a_batch_saliency.shape, \"saliency_list\")\n",
    "\n",
    "# # Preparar los datos para la evaluación\n",
    "# data_batch = {\n",
    "#     'x_batch': filtered_reviews,  # Cambiar 'reviews' a 'x_batch'\n",
    "#     'y_batch': filtered_labels     # Cambiar 'labels' a 'y_batch'\n",
    "# }\n",
    "# # Generar lotes a partir del diccionario de datos\n",
    "# batches = metric_fidelity.generate_batches(data_batch, BATCH_SIZE)\n",
    "# print(batches, \"batchessssssssssssssssssssssssssssssssssssssssss\")\n",
    "# # Evaluar usando general_preprocess y luego calcular las puntuaciones\n",
    "# for batch in batches:\n",
    "#     x_batch = np.array(batch['x_batch'])\n",
    "#     y_batch = np.array(batch['y_batch'])\n",
    "\n",
    "\n",
    "#     print(x_batch.shape, \" ver dimencoonessssssss\")\n",
    "#     # Preprocesar los datos\n",
    "#     metric_fidelity.general_preprocess(roberta_model, x_batch, y_batch, a_batch_saliency, s_batch=None, channel_first=false,\n",
    "#                                        explain_func=None, explain_func_kwargs={}, model_predict_kwargs={}, softmax=false, device=None, custom_batch=None)\n",
    "\n",
    "#     # Aquí puedes realizar la evaluación usando la métrica FaithfulnessEstimate\n",
    "#     scores = metric_fidelity(roberta_model, x_batch, y_batch)\n",
    "\n",
    "#     print(\"Scores:\", scores)\n",
    "\n",
    "\n",
    "# Convertir a arreglos de NumPy\n",
    "\n",
    "\n",
    "a_batch_saliency = np.array(saliency_list)\n",
    "print(a_batch_saliency.shape, \"a_batch_saliency\")\n",
    "print(a_batch_saliency, \"a_batch_saliency\")\n",
    "\n",
    "x_batch = np.array(filtered_reviews)\n",
    "print(x_batch_dataset.shape, \"x_batch_dataset\")\n",
    "print(x_batch_dataset, \"x_batch_dataset\")\n",
    "\n",
    "print(x_batch.shape, \"x_batch\")\n",
    "print(x_batch, \"x_batch\")\n",
    "\n",
    "y_batch = np.array(filtered_labels)\n",
    "print(y_batch.shape, \"y_batch\")\n",
    "print(y_batch, \"y_batch\")\n",
    "\n",
    "\n",
    "print(filtered_reviews)\n",
    "\n",
    "\n",
    "# # Comprobar dimensiones nuevamente\n",
    "\n",
    "\n",
    "# print(\"Dimensiones de a_batch_saliency:\", a_batch_saliency.shape)\n",
    "\n",
    "\n",
    "\n",
    "# saliency_list.append(saliency_values)\n",
    "\n",
    "\n",
    "\n",
    "# # Convertir a arreglos de NumPy y guardar\n",
    "\n",
    "\n",
    "# a_batch_saliency = np.array(saliency_list)\n",
    "\n",
    "\n",
    "# print(\"Dimensiones de a_batch_saliency:\", a_batch_saliency.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Tokenizar los textos\n",
    "inputs = tokenizer(filtered_reviews, return_tensors='pt',\n",
    "                   padding=True, truncation=True)\n",
    "roberta_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = roberta_model(**inputs)\n",
    "    logits = outputs.logits  # Acceder a los logits\n",
    "print(logits.shape)\n",
    "# Obtener los embeddings de la capa de embedding\n",
    "with torch.no_grad():\n",
    "    # Extraer los embeddings\n",
    "    x_batch_embeddings = roberta_model.roberta.embeddings(inputs['input_ids'])\n",
    "\n",
    "\n",
    "print(x_batch_embeddings.type)\n",
    "\n",
    "\n",
    "np.save(\"explanations_lime_roberta.npy\", a_batch_saliency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUC', 'AVAILABLE_METRICS', 'AVAILABLE_NORMALISATION_FUNCTIONS', 'AVAILABLE_N_BINS_ALGORITHMS', 'AVAILABLE_PERTURBATION_FUNCTIONS', 'AVAILABLE_SIMILARITY_FUNCTIONS', 'AVAILABLE_XAI_METHODS_CAPTUM', 'AVAILABLE_XAI_METHODS_TF', 'Any', 'AttributionLocalisation', 'AvgSensitivity', 'Callable', 'Completeness', 'Complexity', 'Consistency', 'Continuity', 'DEPRECATED_XAI_METHODS_CAPTUM', 'DEPRECATED_XAI_METHODS_TF', 'Dict', 'EffectiveComplexity', 'EfficientMPRT', 'FaithfulnessCorrelation', 'FaithfulnessEstimate', 'Final', 'Focus', 'IROF', 'Infidelity', 'InputInvariance', 'List', 'LocalLipschitzEstimate', 'MPRT', 'Mapping', 'MaxSensitivity', 'Metric', 'ModelInterface', 'ModelParameterRandomisation', 'Monotonicity', 'MonotonicityCorrelation', 'NonSensitivity', 'Optional', 'PixelFlipping', 'PointingGame', 'PyTorchModel', 'ROAD', 'RandomLogit', 'RegionPerturbation', 'RelativeInputStability', 'RelativeOutputStability', 'RelativeRepresentationStability', 'RelevanceMassAccuracy', 'RelevanceRankAccuracy', 'Selectivity', 'SensitivityN', 'Sequence', 'SmoothMPRT', 'Sparseness', 'Sufficiency', 'T', 'TensorFlowModel', 'TopKIntersection', 'Tuple', 'Type', 'TypeVar', 'Union', 'abs_difference', 'asserts', 'attribution_localisation', 'auc', 'available_categories', 'available_methods_captum', 'available_methods_tf_explain', 'available_metrics', 'available_normalisation_functions', 'available_perturbation_functions', 'available_similarity_functions', 'avg_sensitivity', 'axiomatic', 'base', 'baseline_replacement_by_blur', 'baseline_replacement_by_indices', 'baseline_replacement_by_shift', 'blur_at_indices', 'calculate_auc', 'completeness', 'complexity', 'complexity_func', 'consistency', 'continuity', 'copy', 'correlation_kendall_tau', 'correlation_pearson', 'correlation_spearman', 'cosine', 'create_patch_slice', 'csc_matrix', 'cv2', 'denormalise', 'difference', 'discretise_func', 'distance_chebyshev', 'distance_euclidean', 'distance_manhattan', 'effective_complexity', 'efficient_mprt', 'evaluate', 'evaluation', 'expand_attribution_channel', 'expand_indices', 'explain', 'explanation_func', 'faithfulness', 'faithfulness_correlation', 'faithfulness_estimate', 'felzenszwalb', 'filter_compatible_patch_sizes', 'focus', 'functions', 'gaussian_noise', 'get_baseline_dict', 'get_baseline_value', 'get_features_in_step', 'get_leftover_shape', 'get_name', 'get_nr_patches', 'get_superpixel_segments', 'get_wrapped_model', 'helpers', 'identity', 'infer_attribution_axes', 'infer_channel_first', 'infidelity', 'input_invariance', 'irof', 'lil_matrix', 'lipschitz_constant', 'local_lipschitz_estimate', 'localisation', 'loss_func', 'make_channel_first', 'make_channel_last', 'max_sensitivity', 'metrics', 'model_interface', 'monotonicity', 'monotonicity_correlation', 'mprt', 'mse', 'n_bins_func', 'no_perturbation', 'noisy_linear_imputation', 'non_sensitivity', 'norm_func', 'normalise_by_average_second_moment_estimate', 'normalise_by_max', 'normalise_by_negative', 'normalise_func', 'np', 'offset_coordinates', 'perturb_batch', 'perturb_func', 'pixel_flipping', 'pointing_game', 'pytorch_model', 'random', 'random_logit', 'randomisation', 're', 'region_perturbation', 'relative_input_stability', 'relative_output_stability', 'relative_representation_stability', 'relevance_mass_accuracy', 'relevance_rank_accuracy', 'road', 'robustness', 'rotation', 'scipy', 'selectivity', 'sensitivity_n', 'similarity_func', 'skimage', 'slic', 'smooth_mprt', 'sparseness', 'spsolve', 'squared_difference', 'ssim', 'sufficiency', 'sys', 'tf', 'tf_model', 'top_k_intersection', 'torch', 'translation_x_direction', 'translation_y_direction', 'uniform_noise', 'util', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "import quantus\n",
    "\n",
    "# Listar todas las métricas disponibles en quantus\n",
    "available_metrics = [attr for attr in dir(quantus) if not attr.startswith('_')]\n",
    "print(available_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de x_batch: (8,)\n",
      "Dimensiones de : (8,)\n",
      "Dimensiones de a_batch_saliency: (8, 10, 2)\n",
      "Dimensiones de embedding: torch.Size([8, 27, 768])\n",
      "a_batch_saliency: [[[ 4.00000000e+00  7.90321762e-02]\n",
      "  [ 2.00000000e+00  5.76310947e-02]\n",
      "  [ 6.00000000e+00  5.76310947e-02]\n",
      "  [ 1.00000000e+01  5.11234429e-02]\n",
      "  [ 5.00000000e+00  5.11234429e-02]\n",
      "  [ 0.00000000e+00 -2.79087333e-02]\n",
      "  [ 9.00000000e+00 -2.79087333e-02]\n",
      "  [ 1.00000000e+00 -2.14010815e-02]\n",
      "  [ 8.00000000e+00  1.52457859e-02]\n",
      "  [ 3.00000000e+00  6.50765176e-03]]\n",
      "\n",
      " [[ 9.00000000e+00  5.60289742e-02]\n",
      "  [ 8.00000000e+00  3.95943188e-02]\n",
      "  [ 3.00000000e+00 -1.64346554e-02]\n",
      "  [ 2.00000000e+00  1.48726130e-02]\n",
      "  [ 5.00000000e+00  1.48726130e-02]\n",
      "  [ 7.00000000e+00  1.48726130e-02]\n",
      "  [ 1.20000000e+01  1.48726130e-02]\n",
      "  [ 1.50000000e+01  1.48726130e-02]\n",
      "  [ 0.00000000e+00 -1.56204241e-03]\n",
      "  [ 1.00000000e+00 -1.56204241e-03]]\n",
      "\n",
      " [[ 2.00000000e+00  4.77117669e-02]\n",
      "  [ 4.00000000e+00  4.77117669e-02]\n",
      "  [ 6.00000000e+00  4.77117669e-02]\n",
      "  [ 1.30000000e+01  4.77117669e-02]\n",
      "  [ 3.00000000e+00  3.27496380e-02]\n",
      "  [ 9.00000000e+00  3.27496380e-02]\n",
      "  [ 8.00000000e+00  2.97853856e-02]\n",
      "  [ 5.00000000e+00 -1.79263813e-02]\n",
      "  [ 0.00000000e+00 -1.49621289e-02]\n",
      "  [ 1.00000000e+00 -1.49621289e-02]]\n",
      "\n",
      " [[ 1.00000000e+00  1.09636359e-01]\n",
      "  [ 2.00000000e+00  1.09636359e-01]\n",
      "  [ 4.00000000e+00  1.09636359e-01]\n",
      "  [ 0.00000000e+00  7.40262619e-02]\n",
      "  [ 5.00000000e+00 -4.25539393e-02]\n",
      "  [ 3.00000000e+00 -3.54479855e-02]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.00000000e+00  2.62155346e-01]\n",
      "  [ 3.00000000e+00  1.97309172e-01]\n",
      "  [ 4.00000000e+00 -8.42555973e-02]\n",
      "  [ 0.00000000e+00 -6.48461737e-02]\n",
      "  [ 1.00000000e+00  3.49746214e-02]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.00000000e+00  1.53001286e-01]\n",
      "  [ 3.00000000e+00  1.11087788e-01]\n",
      "  [ 0.00000000e+00  7.22961851e-02]\n",
      "  [ 1.00000000e+00 -4.19134985e-02]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 3.00000000e+00  2.00636884e-01]\n",
      "  [ 1.00000000e+00  1.84909427e-01]\n",
      "  [ 2.00000000e+00  1.38777142e-01]\n",
      "  [ 8.00000000e+00 -5.88045619e-02]\n",
      "  [ 7.00000000e+00 -5.88045619e-02]\n",
      "  [ 0.00000000e+00 -4.61322852e-02]\n",
      "  [ 4.00000000e+00  1.57274562e-02]\n",
      "  [ 6.00000000e+00  1.57274562e-02]\n",
      "  [ 5.00000000e+00  3.05517942e-03]\n",
      "  [-1.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 3.00000000e+00  2.72558660e-02]\n",
      "  [ 1.10000000e+01  2.72558660e-02]\n",
      "  [ 1.00000000e+00  2.44314823e-02]\n",
      "  [ 2.00000000e+00  2.44314823e-02]\n",
      "  [ 1.00000000e+01  2.44314823e-02]\n",
      "  [ 0.00000000e+00 -6.16558240e-03]\n",
      "  [ 6.00000000e+00 -2.82438368e-03]\n",
      "  [ 8.00000000e+00 -2.82438368e-03]\n",
      "  [ 9.00000000e+00 -2.82438368e-03]\n",
      "  [ 1.20000000e+01 -2.82438368e-03]]]\n",
      "x_batch_embeddings: tensor([[[ 1.6740e-01, -5.5635e-02, -1.0378e-03,  ..., -8.0542e-02,\n",
      "           7.9418e-02,  1.2842e-02],\n",
      "         [ 6.1638e-01, -6.9065e-02,  1.8472e-01,  ..., -2.0342e-01,\n",
      "          -1.5755e-01,  2.4329e-01],\n",
      "         [ 3.6346e-01, -2.1403e-02,  2.4342e-01,  ..., -3.1945e-02,\n",
      "           1.9821e-02, -1.6860e-01],\n",
      "         ...,\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01]],\n",
      "\n",
      "        [[ 1.6740e-01, -5.5635e-02, -1.0378e-03,  ..., -8.0542e-02,\n",
      "           7.9418e-02,  1.2842e-02],\n",
      "         [ 6.1638e-01, -6.9065e-02,  1.8472e-01,  ..., -2.0342e-01,\n",
      "          -1.5755e-01,  2.4329e-01],\n",
      "         [-1.3032e-01, -1.6593e-01,  6.4578e-02,  ...,  2.7020e-02,\n",
      "          -4.7157e-01,  3.7364e-01],\n",
      "         ...,\n",
      "         [ 4.1433e-01, -2.3613e-01, -3.5989e-03,  ...,  2.5241e-01,\n",
      "           2.0164e-01, -2.0136e-01],\n",
      "         [ 3.8338e-01, -1.3754e-01, -1.7700e-04,  ...,  1.7849e-01,\n",
      "           9.6293e-02, -7.4082e-02],\n",
      "         [ 1.1362e-01, -2.5396e-01,  1.3745e-01,  ...,  3.9496e-01,\n",
      "           2.1597e-01, -2.1803e-01]],\n",
      "\n",
      "        [[ 1.6740e-01, -5.5635e-02, -1.0378e-03,  ..., -8.0542e-02,\n",
      "           7.9418e-02,  1.2842e-02],\n",
      "         [ 6.1638e-01, -6.9065e-02,  1.8472e-01,  ..., -2.0342e-01,\n",
      "          -1.5755e-01,  2.4329e-01],\n",
      "         [ 1.5713e-01,  5.9067e-02,  8.8799e-02,  ...,  2.3004e-01,\n",
      "          -1.1120e-01,  7.4454e-02],\n",
      "         ...,\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6740e-01, -5.5635e-02, -1.0378e-03,  ..., -8.0542e-02,\n",
      "           7.9418e-02,  1.2842e-02],\n",
      "         [-2.5114e-01, -1.4788e-01, -2.1139e-02,  ..., -1.9978e-01,\n",
      "          -1.5624e-01,  8.1853e-01],\n",
      "         [-1.9116e-01, -2.5325e-01,  9.5959e-02,  ...,  5.4789e-01,\n",
      "          -2.8309e-01, -1.6600e-01],\n",
      "         ...,\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01]],\n",
      "\n",
      "        [[ 1.6740e-01, -5.5635e-02, -1.0378e-03,  ..., -8.0542e-02,\n",
      "           7.9418e-02,  1.2842e-02],\n",
      "         [ 1.0655e-01,  3.0423e-01,  2.8167e-01,  ..., -1.8813e-01,\n",
      "          -2.6378e-01, -2.0364e-02],\n",
      "         [ 1.1760e-01, -2.9478e-01,  2.9834e-04,  ..., -3.2587e-01,\n",
      "          -8.7276e-02, -7.7460e-02],\n",
      "         ...,\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01]],\n",
      "\n",
      "        [[ 1.6740e-01, -5.5635e-02, -1.0378e-03,  ..., -8.0542e-02,\n",
      "           7.9418e-02,  1.2842e-02],\n",
      "         [ 6.1638e-01, -6.9065e-02,  1.8472e-01,  ..., -2.0342e-01,\n",
      "          -1.5755e-01,  2.4329e-01],\n",
      "         [ 2.0687e-01, -2.4538e-01,  3.0819e-01,  ...,  7.7327e-03,\n",
      "          -4.6792e-01,  1.8361e-01],\n",
      "         ...,\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01],\n",
      "         [ 1.6245e-01,  1.7417e-01, -2.7645e-01,  ..., -6.6525e-02,\n",
      "           1.3654e-01, -4.0555e-01]]])\n",
      "Dimensiones a_batch_saliency después del relleno: (8, 10)\n",
      "Dimensiones x_batch_embeddings después del relleno: (8, 10)\n",
      "a_batch_saliency_padded: (8, 10)\n",
      "x_batch_embeddings_padded: (8, 10)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RobertaForSequenceClassification' object has no attribute 'shape_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 89\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_batch_embeddings_padded:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_batch_embeddings_padded\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Transformar a un formato adecuado\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# x_batch_embeddings_reduced = x_batch_embeddings_padded.mean(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# a_batch_saliency_padded_np = np.array(a_batch_saliency_padded)\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Evaluar la métrica\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m scores_fidelity \u001b[38;5;241m=\u001b[39m \u001b[43mmetric_fidelity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroberta_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch_embeddings_padded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma_batch_saliency_padded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     95\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Imprimir los resultados de la evaluación\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScores de Estimación de Fidelidad:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores_fidelity)\n",
      "File \u001b[1;32mc:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\quantus\\metrics\\faithfulness\\faithfulness_estimate.py:380\u001b[0m, in \u001b[0;36mFaithfulnessEstimate.evaluate_batch\u001b[1;34m(self, model, x_batch, y_batch, a_batch, **kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_batch\u001b[39m(\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    351\u001b[0m     model: ModelInterface,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    This method performs XAI evaluation on a single batch of explanations.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m    For more information on the specific logic, we refer the metric’s initialisation docstring.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        The evaluation results.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 380\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x, y, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_batch, y_batch, a_batch)\n\u001b[0;32m    382\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\quantus\\metrics\\faithfulness\\faithfulness_estimate.py:296\u001b[0m, in \u001b[0;36mFaithfulnessEstimate.evaluate_instance\u001b[1;34m(self, model, x, y, a)\u001b[0m\n\u001b[0;32m    293\u001b[0m a_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39ma)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# Predict on input.\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m x_input \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_input\u001b[49m(x, x\u001b[38;5;241m.\u001b[39mshape, channel_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    297\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(x_input)[:, y])\n\u001b[0;32m    299\u001b[0m n_perturbations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(a_indices), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_in_step))\n",
      "File \u001b[1;32mc:\\Users\\naybv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RobertaForSequenceClassification' object has no attribute 'shape_input'"
     ]
    }
   ],
   "source": [
    "import quantus\n",
    "from quantus.metrics.faithfulness.faithfulness_estimate import FaithfulnessEstimate\n",
    "\n",
    "\n",
    "\n",
    "# Dimensiones transformadas: (1407, 10)\n",
    "\n",
    "\n",
    "\n",
    "# Crear una instancia de la métrica Estimación de Fidelidad\n",
    "\n",
    "\n",
    "metric_fidelity = quantus.FaithfulnessEstimate()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Dimensiones de x_batch:\", x_batch.shape)\n",
    "\n",
    "\n",
    "print(\"Dimensiones de :\", y_batch.shape)\n",
    "\n",
    "\n",
    "print(\"Dimensiones de a_batch_saliency:\", a_batch_saliency.shape)\n",
    "print(\"Dimensiones de embedding:\", x_batch_embeddings[:, :, :].shape)\n",
    "\n",
    "print(\"a_batch_saliency:\", a_batch_saliency)\n",
    "print(\"x_batch_embeddings:\", x_batch_embeddings)\n",
    "\n",
    "\n",
    "def pad_arrays_to_max_shape(array1, array2):\n",
    "    # Obtener las formas de ambos arrays\n",
    "    shape1 = array1.shape\n",
    "    shape2 = array2.shape\n",
    "\n",
    "    # Determinar la nueva forma\n",
    "    new_shape = []\n",
    "\n",
    "    for dim1, dim2 in zip(shape1, shape2):\n",
    "        new_shape.append(max(dim1, dim2))\n",
    "\n",
    "    # Rellenar array1 si es necesario\n",
    "    if shape1 != tuple(new_shape):\n",
    "        padding_width = [(0, new_shape[i] - shape1[i])\n",
    "                         for i in range(len(shape1))]\n",
    "        array1 = np.pad(array1, padding_width,\n",
    "                        mode='constant', constant_values=0)\n",
    "\n",
    "    # Rellenar array2 si es necesario\n",
    "    if shape2 != tuple(new_shape):\n",
    "        padding_width = [(0, new_shape[i] - shape2[i])\n",
    "                         for i in range(len(shape2))]\n",
    "        array2 = np.pad(array2, padding_width,\n",
    "                        mode='constant', constant_values=0)\n",
    "\n",
    "    return array1, array2\n",
    "\n",
    "\n",
    "# Llamar a la función para ajustar las dimensiones\n",
    "a_batch_saliency_padded, x_batch_embeddings_padded = pad_arrays_to_max_shape(\n",
    "    a_batch_saliency[:, :, 0], logits)\n",
    "# Verificar las nuevas dimensiones\n",
    "print(\"Dimensiones a_batch_saliency después del relleno:\",\n",
    "      a_batch_saliency_padded.shape)  # Esperado: (8, 27, 768)\n",
    "print(\"Dimensiones x_batch_embeddings después del relleno:\",\n",
    "      x_batch_embeddings_padded.shape)  # Esperado: (8, 27, 768)\n",
    "\n",
    "print(\"a_batch_saliency_padded:\", a_batch_saliency_padded.shape)\n",
    "print(\"x_batch_embeddings_padded:\", x_batch_embeddings_padded.shape)\n",
    "\n",
    "\n",
    "# Transformar a un formato adecuado\n",
    "\n",
    "# x_batch_embeddings_reduced = x_batch_embeddings_padded.mean(\n",
    "#     axis=2)  # Promediar sobre la dimensión del embedding\n",
    "# a_batch_saliency_reduced = a_batch_saliency_padded.mean(\n",
    "#     axis=2)  # Promediar sobre la dimensión del embedding\n",
    "# # x_batch_embeddings_reduced[:,:,0]\n",
    "# x_batch_embeddings_reduced_long = x_batch_embeddings_reduced.long()\n",
    "# # a_batch_saliency_reduced\n",
    "# print(x_batch_embeddings_reduced_long.shape)\n",
    "\n",
    "# # Convertir a tensores si es necesario\n",
    "# x_batch_embeddings_padded_np = np.array(x_batch_embeddings_padded)\n",
    "# a_batch_saliency_padded_np = np.array(a_batch_saliency_padded)\n",
    "# Evaluar la métrica\n",
    "\n",
    "\n",
    "\n",
    "scores_fidelity = metric_fidelity.evaluate_batch(\n",
    "    model=roberta_model,\n",
    "    x_batch=x_batch_embeddings_padded,\n",
    "    y_batch=y_batch,\n",
    "    a_batch=a_batch_saliency_padded,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# Imprimir los resultados de la evaluación\n",
    "print(\"Scores de Estimación de Fidelidad:\", scores_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantus\n",
    "import torch\n",
    "\n",
    "# Supongamos que ya tienes las siguientes variables definidas:\n",
    "# x_batch, y_batch, a_batch_saliency, embeddings\n",
    "\n",
    "# Crear una instancia de la métrica Estimación de Fidelidad\n",
    "metric_fidelity = quantus.FaithfulnessCorrelation()\n",
    "print(x_batch)\n",
    "# Obtener las dimensiones necesarias\n",
    "batch_size = x_batch_reduced.shape[0]  # Número de batches\n",
    "desired_length = x_batch_reduced.shape[1]  # Longitud deseada para x_batch\n",
    "\n",
    "# Transformar a un formato adecuado\n",
    "# Seleccionar el primer valor del embedding (por ejemplo, el primer token)\n",
    "# Esto tendrá forma (batch_size, hidden_size)\n",
    "x_batch_reduced = embeddings[:, 0, :]\n",
    "\n",
    "# Asegúrate de que a_batch_saliency_reduced tenga la misma forma\n",
    "# Esto tiene forma (3, 10)\n",
    "a_batch_saliency_reduced = a_batch_saliency[:, :, 1]\n",
    "# Convertir a_batch_saliency_reduced a un tensor si es un ndarray\n",
    "if isinstance(a_batch_saliency_reduced, np.ndarray):\n",
    "    a_batch_saliency_reduced = torch.tensor(a_batch_saliency_reduced)\n",
    "# Crear un nuevo tensor lleno de ceros con la forma deseada\n",
    "new_a_batch_saliency = torch.zeros((batch_size, desired_length))\n",
    "\n",
    "# Copiar los valores de a_batch_saliency_reduced al nuevo tensor\n",
    "new_a_batch_saliency[:, :a_batch_saliency_reduced.shape[1]\n",
    "                     ] = a_batch_saliency_reduced\n",
    "new_a_batch_saliency = np.array(new_a_batch_saliency)\n",
    "# Verificar dimensiones después del relleno\n",
    "print(\"Dimensiones transformadas:\",\n",
    "      new_a_batch_saliency.shape)  # Debería ser (3, 27)\n",
    "print(x_batch_reduced)\n",
    "print(new_a_batch_saliency)\n",
    "\n",
    "# Debería ser (3, hidden_size)\n",
    "print(\"Dimensiones de x_batch_reduced:\", x_batch_reduced.shape)\n",
    "# Debería ser (3, desired_length)\n",
    "print(\"Dimensiones de new_a_batch_saliency:\", new_a_batch_saliency.shape)\n",
    "\n",
    "# Evaluar la métrica\n",
    "scores_fidelity = metric_fidelity(\n",
    "    model=roberta_model,\n",
    "    x_batch=x_batch_reduced,\n",
    "    y_batch=y_batch,\n",
    "    a_batch=new_a_batch_saliency,\n",
    "    device='cpu',\n",
    "    subset_size=min(10, x_batch_reduced.shape[0])\n",
    ")\n",
    "\n",
    "# Imprimir los resultados de la evaluación\n",
    "print(\"Scores de Estimación de Fidelidad:\", scores_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from utils.utils import load_dataset, save_explanation\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from models.roberta_model import classify_comment, load_roberta_model_main\n",
    "import torch\n",
    "import quantus\n",
    "from quantus.metrics.faithfulness.faithfulness_estimate import FaithfulnessEstimate\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "dataset = load_dataset(\n",
    "    \"models/relevance_classification/dataset/facebook_labeled.csv\", sep=\",\")\n",
    "\n",
    "# Cargar el modelo RoBERTa preentrenado\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"modelo de ray mejorado(SHAP)/\")\n",
    "roberta_model.eval()  # Poner el modelo en modo de evaluación\n",
    "\n",
    "# Configurar el explicador LIME\n",
    "explainer_roberta = LimeTextExplainer(class_names=['not relevant', 'relevant'])\n",
    "\n",
    "# Seleccionar una instancia del conjunto de datos para explicar\n",
    "instance_roberta = dataset['Review'].iloc[0]\n",
    "\n",
    "# Generar la explicación usando LIME\n",
    "explanation_roberta = explainer_roberta.explain_instance(\n",
    "    instance_roberta,\n",
    "    classify_comment\n",
    ")\n",
    "print(\"Etiquetas disponibles:\", explainer_roberta.available_labels())\n",
    "\n",
    "# Extraer las características y las puntuaciones de relevancia del explicador LIME\n",
    "a_batch_saliency = explanation_roberta.as_map(\n",
    ")[explanation_roberta.top_labels[0]]\n",
    "\n",
    "# Convertir a un formato adecuado para Quantus\n",
    "# Aquí debes asegurarte de que a_batch_saliency esté en el formato correcto (ndarray)\n",
    "\n",
    "# Convertir a_batch_saliency a un ndarray si es necesario\n",
    "a_batch_saliency_array = np.array(\n",
    "    [saliency[1] for saliency in a_batch_saliency])\n",
    "\n",
    "# Crear un objeto de la métrica Estimación de Fidelidad\n",
    "metric_fidelity = FaithfulnessEstimate()\n",
    "\n",
    "# Preparar x_batch y y_batch para la evaluación (asegúrate de que estén en el formato correcto)\n",
    "x_batch = [instance_roberta]  # Aquí deberías tener tus instancias como texto\n",
    "# La etiqueta predicha por tu modelo\n",
    "y_batch = [classify_comment(instance_roberta)]\n",
    "\n",
    "# Evaluar la métrica de fidelidad\n",
    "scores_fidelity = metric_fidelity(\n",
    "    model=roberta_model,\n",
    "    x_batch=x_batch,\n",
    "    y_batch=y_batch,\n",
    "    a_batch=a_batch_saliency_array,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Imprimir los resultados de la evaluación de fidelidad\n",
    "print(\"Scores de Estimación de Fidelidad:\", scores_fidelity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
